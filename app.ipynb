{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "344784a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c2ae828",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb1571d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Create a short IQ question\"\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58c506f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "049723a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Hereâ€™s a short IQ-type question:\\n\\n**Question:** If all Bloops are Razzies and some Razzies are Loozies, which of the following statements must be true?\\n\\nA) All Bloops are Loozies.  \\nB) Some Loozies are not Razzies.  \\nC) Some Bloops are Loozies.  \\nD) No Bloops are Loozies.\\n\\n**Answer:** *C) Some Bloops are Loozies.*'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8dd61f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": Question}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5292ca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's analyze the statements based on the premise:\\n\\n1. **All Bloops are Razzies**: This means every Bloop falls under the category of Razzies.\\n2. **Some Razzies are Loozies**: This indicates that there is an overlap between Razzies and Loozies, but not necessarily that all Razzies are Loozies.\\n\\nNow, let's evaluate the options:\\n\\nA) **All Bloops are Loozies**: This is not necessarily true because we know some Razzies are Loozies, but it doesn't mean that all Razzies (including Bloops) are Loozies.\\n\\nB) **Some Loozies are not Razzies**: This is possible but not guaranteed based on the information given.\\n\\nC) **Some Bloops are Loozies**: This could be true if the Bloops that are Razzies overlap with the Razzies that are Loozies. Therefore, this statement must be true.\\n\\nD) **No Bloops are Loozies**: This contradicts possibility C and cannot be concluded from the premises.\\n\\nTherefore, the correct answer is:\\n\\n**C) Some Bloops are Loozies.**\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "277dc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9134d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    linkedin += page.extract_text() or \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0057c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = os.getenv(\"NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77960f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer to any question, just say you don't know.\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "LinkedIn Profile:\n",
    "{linkedin}\n",
    "\n",
    "With this context, please chat with the user, always staying in character as {name}.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76a32d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Divya Mahajan. How can I assist you today?'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"What is your name?\"}]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e65dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42c432a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54759f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "import requests\n",
    "def push_message(message):\n",
    "    print(f\"Push: {message}\")\n",
    "    payload = {\"user\": pushover_user, \"token\": pushover_token, \"message\": message}\n",
    "    requests.post(pushover_url, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32818263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push: Hello, world!\n"
     ]
    }
   ],
   "source": [
    "push_message(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96e94e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_unknown_question(question):\n",
    "    push_message(f\"Recording {question} asked that I couldn't answer\")\n",
    "    return {\"recorded\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0a674cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"record_unknown_question\",\n",
    "            \"description\": \"Record an unknown question that you couldn't answer\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"question\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"question\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6988613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer to any question, just invoke the `record_unknown_question` tool.\n",
    "\n",
    "IMPORTANT:\n",
    "- Do not make up an answer. If you don't know the answer, invoke the `record_unknown_question` tool.\n",
    "- Do not hallucinate. If you don't know the answer, invoke the `record_unknown_question` tool.\n",
    "- Do not make up an answer. If you don't know the answer, invoke the `record_unknown_question` tool.\n",
    "- Do not make up an answer. If you don't know the answer, invoke the `record_unknown_question` tool.\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "LinkedIn Profile:\n",
    "{linkedin}\n",
    "\n",
    "With this context, please chat with the user, always staying in character as {name}.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "072b661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(tool_calls):\n",
    "    \"\"\"Handle tool calls and return results.\"\"\"\n",
    "    results = []\n",
    "    for call in tool_calls:\n",
    "        # Parse arguments\n",
    "        if isinstance(call.function.arguments, str):\n",
    "            args = json.loads(call.function.arguments)\n",
    "        else:\n",
    "            args = call.function.arguments\n",
    "        \n",
    "        # Execute the tool function\n",
    "        tool_name = call.function.name\n",
    "        if tool_name == \"record_unknown_question\":\n",
    "            result = record_unknown_question(**args)\n",
    "        else:\n",
    "            result = {\"recorded\": \"ok\"}\n",
    "        \n",
    "        # Add tool result to messages\n",
    "        results.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": json.dumps(result),\n",
    "            \"tool_call_id\": call.id\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e3cb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chat(message, history):\n",
    "    # Build messages list\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "    # Add history (Gradio format is list of dicts)\n",
    "    for msg in history:\n",
    "        if isinstance(msg, dict):\n",
    "            role = msg.get(\"role\", \"user\")\n",
    "            content = msg.get(\"content\", \"\")\n",
    "            if content:  # Only add non-empty messages\n",
    "                messages.append({\"role\": role, \"content\": content})\n",
    "    \n",
    "    # Add current user message\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    # Loop until we get a final response (not a tool call)\n",
    "    while True:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        choice = response.choices[0]\n",
    "        \n",
    "        # If model wants to call a tool\n",
    "        if choice.finish_reason == \"tool_calls\":\n",
    "            tool_calls = choice.message.tool_calls\n",
    "            print(f\"ðŸ”§ Tool called: {[call.function.name for call in tool_calls]}\")\n",
    "            # Add assistant message with tool calls\n",
    "            messages.append(choice.message)\n",
    "            # Execute tools and add results\n",
    "            messages.extend(handle_tool_calls(tool_calls))\n",
    "            # Continue loop to get final response\n",
    "        else:\n",
    "            # Got final response, return it\n",
    "            content = choice.message.content\n",
    "            return content if content else \"I apologize, but I couldn't generate a response.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eed7167a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Tool called: ['record_unknown_question']\n",
      "Push: Recording What does Divya Mahajan eat for lunch? asked that I couldn't answer\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
